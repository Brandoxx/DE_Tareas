```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## CI0131 Diseño de experimentos - I Ciclo 2024

## Laboratorio 6: Regresión Lineal Simple

### Integrantes:

-   Brandon Mora Umaña - C15179
-   A. Badilla Olivas - B80874

## Primera parte

### Pregunta 1

Para mostrar la relación entre la variable `runs` y otra variable numérica, se utilizaría un **diagrama de dispersión**.

```{r message=FALSE, warning=FALSE}
download.file("http://www.openintro.org/stat/data/mlb11.RData", destfile = "mlb11.RData")
load("mlb11.RData")
mlb11
```

```{r fig.cap="Relación entre Carreras Anotadas (runs) y Turnos al Bate (at_bats)"}
plot(mlb11$at_bats, mlb11$runs, xlab = "Turnos al Bate (at_bats)", ylab = "Carreras Anotadas (runs)")
```

La relación entre `runs` y `at_bats` parece ser **lineal y positiva**, aunque con cierta dispersión. A medida que aumentan los turnos al bate, tienden a aumentar las carreras anotadas.

El coeficiente de correlación entre `runs` y `at_bats` es:

```{r}
cor(mlb11$runs, mlb11$at_bats)
```

Esto confirma una **correlación positiva moderadamente fuerte** entre las variables.

### Pregunta 2
Escribimos las siguientes funciones para gráficar además de la linea los residuales de manera más bonita.
```{r fig.cap="Relación entre Carreras Anotadas (runs) y Turnos al Bate (at_bats) con Residuos Cuadrados", fig.height=4, fig.width=6}
# Function to plot data points and optionally show squares of residuals
plot_ss <- function(x, y, showSquares = FALSE, predefined=FALSE) {
  # Plot the initial scatter plot
  plot(x, y, xlab = "", ylab = "")
  cat("Click twice on the graph to draw a line.\n")
  # Get two points from the user to define the line or use predefined points
  if (predefined)
    user_points <- data.frame(x=c(min(x), max(x)), y=c(min(y), max(y)))
  else 
    user_points <- getUserDefinedLine() 
  # Calculate slope and intercept based on user points
  line_params <- calculateLineParams(user_points)
  
  # Draw the line on the plot
  drawLine(line_params$intercept, line_params$slope)
  
  # Optionally, show squares of residuals
  if(showSquares) {
    showResidualSquares(x, y, line_params$slope, line_params$intercept)
  }
  
  # Calculate and display the sum of squares of residuals
  ss_res <- calculateSSRes(x, y, line_params$slope, line_params$intercept)
  cat("Sum of squares of residuals:", ss_res, "\n")
  cat("Intercept:", line_params$intercept, "Slope:", line_params$slope, "\n")
}
# Function to get two points from the user to define the line
getUserDefinedLine <- function() {
  pts <- locator(n = 2)
  return(pts)
}
# Function to calculate slope and intercept from two points
calculateLineParams <- function(pts) {
  slope <- (pts$y[2] - pts$y[1]) / (pts$x[2] - pts$x[1])
  intercept <- pts$y[1] - slope * pts$x[1]
  return(list(slope = slope, intercept = intercept))
}
# Function to draw a line given slope and intercept
drawLine <- function(intercept, slope) {
  abline(a = intercept, b = slope)
}
# Function to show squares of residuals
showResidualSquares <- function(x, y, slope, intercept) {
  # Here we plot the actual data
  points(x = x, y = y, pch = 16, cex = 1.2)
  # here we plot the points sample frome the line we created
  points(x = x, y = intercept + slope * x, col = "red", pch = 16, cex = 1.2)
  # here we plot line segments from the line  and the actual data.
  segments(x0 = x, y0 = y, x1 = x, y1 = intercept + slope * x, col = "blue", lty = 2)
}
# Function to calculate the sum of squares of residuals
calculateSSRes <- function(x, y, slope, intercept) {
  y_pred <- intercept + slope * x
  ss_res <- sum((y - y_pred)^2)
  return(ss_res)
}

plot_ss(x = mlb11$at_bats, y = mlb11$runs, showSquares = TRUE, predefined=TRUE)
```

La menor suma de cuadrados que se logró obtener fue **144425.8**. Como se mencionó, es difícil igualar la suma de cuadrados del modelo lineal (123721.9) de forma manual.

### Pregunta 3

```{r}
m1 <- lm(runs ~ at_bats, data = mlb11)
summary(m1)
```

### Pregunta 4

La fórmula del modelo lineal obtenido es:

ŷ = -2789.2429 + 0.6305 \* at_bats

### Pregunta 5

```{r}
m2 <- lm(runs ~ homeruns, data = mlb11)
summary(m2)
```

La ecuación del modelo lineal para `runs` en función de `homeruns` es:

ŷ = 415.2389 + 1.8345 \* homeruns

-   **Pendiente:** La pendiente de 1.8345 indica que, por cada homerun adicional que un equipo realiza, se espera que anote 1.83 carreras más, manteniendo constantes las demás variables.

-   **R-cuadrado:** El R-cuadrado de este modelo (0.6266) es mayor que el del modelo con `at_bats` (0.3729). Esto significa que el 62.69% de la variabilidad en las carreras anotadas se explica por la cantidad de homeruns, lo que indica un mejor ajuste que el modelo anterior.

### Pregunta 6

```{r fig.cap="Diagrama de Dispersión con Línea de Mínimos Cuadrados", fig.height=4, fig.width=6}
plot(mlb11$runs ~ mlb11$at_bats, xlab = "Turnos al Bate (at_bats)", ylab = "Carreras Anotadas (runs)")
abline(m1)
```

### Pregunta 7

```{r fig.cap="Gráfico de Residuos vs. Turnos al Bate", fig.height=4, fig.width=6}
plot(m1$residuals ~ mlb11$at_bats, xlab = "Turnos al Bate (at_bats)", ylab = "Residuos")
abline(h = 0, lty = 3)
```

**No parece haber un patrón aparente** en el gráfico de residuos. Los residuos parecen estar distribuidos aleatoriamente alrededor de cero, lo que sugiere que **la condición de independencia de residuos se cumple**.

### Pregunta 8

```{r fig.cap="Histograma de Residuos", fig.height=4, fig.width=6}
hist(m1$residuals)
```

```{r fig.cap="Gráfica de Probabilidad Normal de Residuos", fig.height=4, fig.width=6}
qqnorm(m1$residuals)
qqline(m1$residuals)
```

Tanto el histograma como la gráfica de probabilidad normal sugieren que **la condición de residuos normales se cumple razonablemente**. El histograma muestra una forma aproximadamente simétrica y acampanada, aunque una de las barras en el centro parace desviarse. También, la mayoría de los puntos en la gráfica de probabilidad normal se encuentran cerca de la línea diagonal.

### Pregunta 9

```{r fig.cap="Gráfico de Residuos vs. Valores Ajustados", fig.height=4, fig.width=6}
plot(m1$residuals ~ m1$fitted.values, xlab = "Valores Ajustados", ylab = "Residuos")
abline(h = 0, lty = 3)
```

El gráfico de residuos vs. valores ajustados **no muestra un patrón evidente**, lo que sugiere que **la condición de varianza homogénea de los residuos se cumple**.

## Segunda parte

### Pregunta 10

```{r}
# Crear una tabla vacía para almacenar los resultados
tabla_resultados <- data.frame(
  Variable = character(),
  Correlacion = numeric(),
  Valor_p = numeric(),
  R_cuadrado = numeric(),
  stringsAsFactors = FALSE
)

# Iterar sobre las variables tradicionales
for (variable in c("at_bats", "hits", "homeruns", "bat_avg", "strikeouts", "stolen_bases", "wins")) {
  # Ajustar el modelo lineal
  formula <- as.formula(paste("runs ~", variable))
  modelo <- lm(formula, data = mlb11)
  
  # Extraer los resultados
  correlacion <- cor(mlb11$runs, mlb11[[variable]])
  valor_p <- summary(modelo)$coefficients[2, 4]
  r_cuadrado <- summary(modelo)$r.squared
  
  # Agregar los resultados a la tabla
  tabla_resultados <- rbind(tabla_resultados, data.frame(
    Variable = variable,
    Correlacion = correlacion,
    Valor_p = valor_p,
    R_cuadrado = r_cuadrado
  ))
}

# Mostrar la tabla
tabla_resultados
```

De acuerdo con los resultados de la tabla, la variable **`bat_avg` (promedio de bateo) parece ser el mejor predictor de `runs`** entre las variables tradicionales. Esto se debe a que presenta el **mayor valor de R-cuadrado (0.6561)**, lo que indica que explica la mayor proporción de la variabilidad en las carreras anotadas. Además, tiene un **valor p muy pequeño**, lo que indica una relación estadísticamente significativa. Por último, también es la que posee la mayor correlación con la varaiable `runs`.

### Pregunta 11

```{r}
# Crear una tabla vacía para almacenar los resultados
tabla_resultados_nuevas <- data.frame(
  Variable = character(),
  Correlacion = numeric(),
  Valor_p = numeric(),
  R_cuadrado = numeric(),
  stringsAsFactors = FALSE
)

# Iterar sobre las nuevas variables
for (variable in c("new_onbase", "new_slug", "new_obs")) {
  # Ajustar el modelo lineal
  formula <- as.formula(paste("runs ~", variable))
  modelo <- lm(formula, data = mlb11)
  
  # Extraer los resultados
  correlacion <- cor(mlb11$runs, mlb11[[variable]])
  valor_p <- summary(modelo)$coefficients[2, 4]
  r_cuadrado <- summary(modelo)$r.squared
  
  # Agregar los resultados a la tabla
  tabla_resultados_nuevas <- rbind(tabla_resultados_nuevas, data.frame(
    Variable = variable,
    Correlacion = correlacion,
    Valor_p = valor_p,
    R_cuadrado = r_cuadrado
  ))
}

# Mostrar la tabla
tabla_resultados_nuevas
```

En general, las **nuevas variables (`new_onbase`, `new_slug`, `new_obs`) son más efectivas para predecir `runs`** que las variables tradicionales. Esto se evidencia en los **valores de R-cuadrado más altos** para las tres nuevas variables en comparación con las variables tradicionales.

El **mejor predictor de `runs` parece ser `new_obs` (suma de porcentaje de embasamiento y porcentaje de slugging)**. Esta variable presenta el **R-cuadrado más alto (0.9349)**, lo que significa que explica una gran proporción de la variabilidad en las carreras anotadas. New obs esta definida como la suma de porcentaje de embasamiento y porcentaje de slugging, ambos con porcentajes de correlación muy altos indicando que sean variables muy significativas para el modelo.

Estos resultados apoyan la premisa de Moneyball, que sugiere que estadísticas como el porcentaje de embasamiento y el porcentaje de slugging son mejores predictores del éxito de un equipo que las estadísticas tradicionales.
